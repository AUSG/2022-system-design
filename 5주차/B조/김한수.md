- [키-값 저장소 설계](#키-값-저장소-설계)
  - [키-값 저장소(key-value store)](#키-값-저장소key-value-store)
  - [단일 key-value store](#단일-key-value-store)
  - [분산 key-value store](#분산-key-value-store)
  - [CAP 정리](#cap-정리)
  - [시스템 컴포넌트](#시스템-컴포넌트)
    - [데이터 파티션](#데이터-파티션)
    - [데이터 다중화(replication)](#데이터-다중화replication)
    - [일관성(consistency)](#일관성consistency)
    - [일관성 불일치 해소(inconsistency resolution)](#일관성-불일치-해소inconsistency-resolution)
    - [장애 처리](#장애-처리)
    - [일시적 장애 처리](#일시적-장애-처리)
    - [영구 장애 처리](#영구-장애-처리)
    - [데이터 센터 장애 처리](#데이터-센터-장애-처리)
    - [시스템 아키텍처 다이어그램](#시스템-아키텍처-다이어그램)
  - [요약](#요약)

# 키-값 저장소 설계

## 키-값 저장소(key-value store)

- `키-값 저장소`(key-value store)
  - 키-캆 데이터베이스라고도 불리는 비 관계형(non-relational) 데이터베이스
  - e.g. AWS DynamoDB, memcached, redis

## 단일 key-value store

- 한 대 서버만을 사용하는 key-value store를 설계하는 것은 쉽다.
- 가장 직관적인 방법은 단순히 메모리에 `해시 테이블`로 저장하는 것이다.
- 그러나 이건 빠른 속도를 보장하지만 모든 데이터를 메모리 안에 두는 것이 불가능할 수 있다.
- **이에 대한 개선책은 다음과 같다**
  - `데이터 압축`(compression)
  - `자주 쓰이는 데이터만 메모리에 두고 나머지는 디스크에 저장`
- 그러나 이렇게 해도 한 대 서버로 부족한 때가 찾아온다. 이런 경우 `분산 key-value store`가 필요하다.

## 분산 key-value store

- `분산 key-value store`는 키-값 쌍을 여러 서버에 분산시키는 탓에 `분산 해시 테이블`이라고도 불린다.
- 분산 시스템을 설계할 때는 `CAP정리`를 이해하고 있어야한다.

## CAP 정리

- `CAP 정리`에 의하면 다음 3가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다
  - `데이터 일관성`(Consistency)
    - 어떤 노드에 접속했느냐에 관계없이 **언제나 같은 데이터를 봐야함**
  - `가용성`(Availability)
    - 일부 노드에 장애가 발생하더라도 **항상 응답을 받을 수 있어야함**
  - `파티션 감내`(Partition tolerance)
    - 네트워크에 파티션이 생기더라도 **시스템은 계속 동작해야함**
    - `파티션` = 두 노드 사이에 통신 장애가 발생함을 의미
- 단 이 중 2가지 정도는 만족할 수 있는데, 다음과 같이 분류해볼 수 있다.

    ![CAP정리](https://user-images.githubusercontent.com/72328687/195560370-67c03865-bbb0-42b9-ab9d-098407fd9f16.png)

  - CA: 일관성 + 가용성
    - 실세계에 CA 시스템은 존재하지 않음
    - 그 이유는 통상 네트워크 장애는 피할 수 없으므로 분산 시스템은 반드시 파티션 문제를 감내할 수 있도록 설계되어야 하기 때문
  - AP 시스템
    - 가용성 + 파티션 감내
  - CP 시스템
    - 일관성 + 파티션 감내
- **결론적으로 요구사항에 맞게 적절한 trade-off를 하는 것이 중요!**

## 시스템 컴포넌트

key-value store 구현에 사용될 핵심 컴포넌트 및 기술들을 살펴보자

### 데이터 파티션

- 데이터 파티션은 다음 두 가지를 중요하게 따져봐야함
  - **데이터를 여러 서버에 고르게 분산할 수 있는가**
  - **노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가**
- 이는 안정 해시를 이용하면 적합하게 풀어낼 수 있음
- 추가로 다음 몇가지를 챙겨볼 수 있음
  - `규모 확장 자동화`(automatic scaling)
  - `다양성`(heterogeneity)
    - 각 서버의 용량에 맞게 가상 노드 수를 조정 가능

### 데이터 다중화(replication)

- **높은 가용성과 안정성 확보를 위해 N개 서버에 비동적으로 replication이 필요**
- 해시 링 위에 어떤 키를 배치한 후 먼저 만나는 N개 서버에 데이터 사본을 보관하는 식으로 N개의 서버를 선정
- **가상 노드 사용 시 실제 replication된 물리 서버의 수가 N보다 작을 수 있으므로 같은 물리 서버를 중복 선택하지 않도록 해야함**
- 데이터 센터 다중화도 중요

### 일관성(consistency)

- **여러 노드에 다중화된 데이터는 적절히 동기화되어야함**
- `정족수 합의`(Quorum Consensus) 프로토콜 등을 이용해 일관성을 보장할 수 있음
  - 정족수 합의에서는 예시로 다음과 같은 변수들을 정해볼 수 있고 각 변수의 빡빡한 정도에 따라
        `엄격한 정족수`, `느슨한 정족수` 라고도 한다
    - **N**: 서버 사본의 개수
    - **W**: 쓰기 연산에 대한 정족수. 쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야함.
    - **R**: 읽기 연산에 대한 정족수. 읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야함.
- **요구사항에 따라 다음과 같은 일관성 모델을 적절히 선택해야함**
  - `강한 일관성`: 클라이언트는 절대 낡은 데이터를 볼 수 없음
  - `약한 일관성`: 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있음
  - `최종 일관성`: 약한 일관성의 한 형태. 결국에는 모든 사본에 최신 데이터가 동기화 됨

### 일관성 불일치 해소(inconsistency resolution)

- 위에서 살펴본 일관성 모델 중 최종 일관성 모델 선택 시, `쓰기 연산에 대한 동시성 이슈`가 생길 수 있음
- 이를 해결하기 위한 방법으로 `데이터 버저닝`을 활용할 수 있음
  - `데이터 버저닝`
    - `버저닝`(versioning)과 `벡터 시계`(vector clock)을 이용해 데이터를 변경할 때 마다 새로운 버전을 만듬. 각 버전의 데이터는 변경 불가능
    - 벡터 시계는[서버, 버전] 순서쌍을 데이터에 붙인 것으로 버전 충돌 판별에 사용됨
    - `벡터 시계 단점`
      - **충돌 감지 및 해소 로직이 클라이언트에 들어가야함 → 복잡도 상승**
      - **[서버, 버전] 순서쌍 개수가 굉장히 빨리 늘어남 → 메모리 대량 소비**
        - 이를 해결하기위해 임계치 설정 후 오래된 순서쌍 제거
        - 그러나 이렇게 하면 이론상 버전 간 선후 관계가 정확하게 결정될 수 없어 충돌 해소 과정의 효율성이 낮아지게 됨
        - 하지만 AWS DynamoDB 관련 문헌에 따르면 실제 서비스에서 그런 문제가 벌어진 걸 발견한 적이 없다고 함. 즉, 대부분의 실 서비스에서 괜찮은 솔루션임

### 장애 처리

- 대규모 시스템에서 장애는 아주 흔하게 벌어지며, 장애를 어떻게 처리할 것이냐가 굉장히 중요.
- 이와 관련해 `우선 장애 감지`(failure detection)기법, `장애 해소`(failure resolution)전략들에 대해서 알아보자
- `장애 감지`
  - 분산 시스템에서 그저 한 대 서버가 죽었다고 바로 서버 A를 장애처리 하진 않음
  - 보통 두 대 이상의 서버가 똑같이 서버 A의 장애를 보고해야 장애 발생으로 간주하곤 함
  - 모든 노드 사이에 멀티캐스팅 채널을 구축해 서버 장애를 감지하는 것이 손쉬운 방법이지만 서버가 많아지면 비효율적..
  - 따라서 `가십 프로토콜`(gossip protocol)같은 분산형 장애 감지 솔루션을 채택하는 편이 효율적
  - `가십 프로토콜`(gossip protocols)
    - 각 노드는 각 멤버 ID와 박동 카운터(heart beat) 쌍을 기론한 멤버십 목록(membership list)를 유지한다.
    - 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.
    - 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다.
    - 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.
    - 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주한다.

### 일시적 장애 처리

- 가십 프로토콜로 장애를 감지한 시스템은 가용성을 보장하기 위해 필요한 조치를 해야한다
- 시스템 특성에 따라 읽기와 쓰기 연산을 금지하는 엄격한 제어 혹은 장애 상태인 서버는 무시하고 몇개의 건강한 서버를 골라 사용하는 느슨하게 제어도 가능함
- **일시적 장애 처리를 할 때 데이터 일관성을 보존하기 위해 장애 서버가 복구되었을 때 그동안 발생한 변경사항을 일괄 반영함**
  - 이를 위해 서버에는 그에 관한 단서(hint)들을 남기고 이런 장애 처리 방안을 단서 후 임시 위탁(hinted handoff)기법이라 부름

### 영구 장애 처리

- 영구 장애 상태에는 `anti-entropy` 프로토콜을 구현해 사본들을 동기화하고 데이터 일관성을 챙겨볼 수 있음
- 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터의 양을 줄이기 위해 해시 트리라고도 불리는 `머클(Merkle) 트리`를 이용해볼 수도 있음

### 데이터 센터 장애 처리

- 데이터 센터 장애를 대비하여 데이터 센터 다중화도 중요
  
### 시스템 아키텍처 다이어그램

- 지금까지 본 내용들을 정리하고 아키텍처 다이어그램을 그려보자
- **주된 기능들**
  - **클라이언트와 두가지 단순한 API로 통신. get(key), put(key, value) 등**
  - **노드는 안정 해시(consistent hash)와 해시 링(hash ring) 위에 분포**
  - **중재자(coordinator)는 클라이언트에게 key-value store에 대한 proxy역할을 하는 노드로 해시 링에 분포된 노드 중 어떤 노드든 중재자가 될 수 있음**
  - **노드를 자동으로 추가, 삭제할 수 있도록 시스템을 완전히 분산**
  - **데이터는 여러 노드에 다중화**
  - **모든 노드가 같은 책임을 지므로 SPOF(Single Point Of Failure)는 존재하지 않음**

![distributed key-value store architecture](https://user-images.githubusercontent.com/72328687/195560376-e16d5514-1092-4e46-a1c3-6d6d4cc83e15.png)

- 완전 분산된 설계를 채택하면, 모든 노드는 다음과 같은 기능을 전부 지원해야함

![distributed key-value store node functions](https://user-images.githubusercontent.com/72328687/195560386-0e10f9c7-fc5b-4983-8036-c6973db265c0.png)

## 요약

- **항상 그렇지만 적절한 상황에 적절한 기술을 활용하는 것이 중요 (trade-off)**

![key-value store summary](https://user-images.githubusercontent.com/72328687/195560357-68895127-cdc2-4576-a4cc-15716843a01e.png)
