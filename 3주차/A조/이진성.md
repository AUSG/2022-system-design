- [3장 - 시스템 설계 면접 공략법](#3장---시스템-설계-면접-공략법)
  - [효과적 면접을 위한 4단계 접근법](#효과적-면접을-위한-4단계-접근법)
    - [1. 문제 이해 및 설계 범위를 확정](#1-문제-이해-및-설계-범위를-확정)
    - [2. 개략적인 설계안 제시 및 동의 구하기](#2-개략적인-설계안-제시-및-동의-구하기)
    - [3. 상세 설계](#3-상세-설계)
    - [4. 마무리](#4-마무리)
  - [Interview Tip](#interview-tip)
    - [해야할 것](#해야할-것)
    - [하지 말아야할 것](#하지-말아야할-것)
    - [시간 배분은 ?](#시간-배분은-)
- [4장 - 처리율 제한 장치의 설계](#4장---처리율-제한-장치의-설계)
  - [1단계 - 문제 이해 및 설계 범위의 확정](#1단계---문제-이해-및-설계-범위의-확정)
  - [2단계 - 개략적인 설계안 제시 및 동의 구하기](#2단계---개략적인-설계안-제시-및-동의-구하기)
  - [3단계 - 상세 설계](#3단계---상세-설계)
  - [마무리](#마무리)

## 3장 - 시스템 설계 면접 공략법

시스템 설계 면접은 두 명의 동료가 모호한 문제를 풀기 위해 협력하여 그 해결책을 찾아내는 과정에 대한 시뮬레이션이다.

- 면접관에 있어서 가장 피하고 싶은 경우는 면접 자리에서 충분한 시그널을 수집하지 못해, 평과 결과를 확정짓지 못하는 경우이다.
- 시스템 설게 면접은 기술적 측면을 평가하는 자리가 아니라, 지원자가 협력에 적합한 자리인지 - 압박이 심한 상황에서도 잘 헤처 나갈 자질이 있는지 - 모호한 문제를 건설적으로 해결할 능력이 있는지 등을 살펴보는 자리
- 훌륭한 면접관은 red flag를 놓치지 않는다.
    - 설계의 순수성(purity)에 집착한 나머지 타협적 결정(tradeoff)를 도외시하고 over-engineering을 하는 경우
    - 완고하거나 편협적인 시각들

### 효과적 면접을 위한 4단계 접근법

#### 1. 문제 이해 및 설계 범위를 확정

1. 요구사항을 완전하게 이해하지 않고 답을 내놓는 행위는 아주 엄청난 부정적 신호(red flag)다.
2. 요구사항을 정확하게 파악하기 위해서 아래와 같은 질문들을 생각해볼 수 있다.
    1. 어떤 기능들을 만들어야 하는지
    2. 제품 사용자 수는 어떻게 되는지
    3. 회사의 규모 성장 추세
    4. 회사가 주로 사용하는 기술 스택은?
3. 뉴스 피드 질문의 예시
    1. 지원 클라이언트
    2. 트래픽 규모
    3. 주요 기능 및 세부 사항 
        1. 정렬 순서
        2. 최대 친구 관계 수
        3. 피드에 이미지나 비디오도 올라올 수 있는지

요구 사항의 모호함을 없애는 것이 가장 중요하다.

#### 2. 개략적인 설계안 제시 및 동의 구하기

- 면접관이 마치 팀원인 것처럼 의견을 구할 것 - 훌륭한 면접관들은 지원자들과 대화하고 설계 과정에서 개입하기를 즐길 것
- 화이트보드나 종이에 핵심 컴포넌트를 포함하는 다이어그램을 그릴 것 (API, CDN, Cache, MQ, Servers)
- 최초 설계안이 시스템 규모에 관계된 제약사항들이 만족하는지 개략적으로 계산해볼 것
- 세부적인 내용 내용은 질문에 따라 다르기에 알아서 잘 판단하자.

뉴스피드의 문제에서..

- 피드 발행 : 사용자가 포스트를 올리면 DB에 기록되고 구독하는 대상의 피드에 뜨는 것
- 피드 생성 : 어떤 사용자가 보는 피드를 시간 순으로 정렬하여 만드는 것

#### 3. 상세 설계

- 개략적인 설계안(청사진)이 마무리되었다면 상세 설계에 대한 컴포넌트 별 우선순위를 면접과 조율해야한다.
- 대부분의 경우 면접관은 시스템 컴포넌트들의 세부사항을 깊이 있게 설명하길 바란다. 해시 함수에 대한 세부사항이나, 지연시간을 줄이는 법 - 온/오프라인 상태 표시를 어떻게 할지 등에 해당한다.
- 불필요하게 세부사항을 설명할 필요는 없다 - edge ranking이나 특정 알고리즘에 대한 구현에 대해서는 굳이 설명할 필요는 없고, 규모 확장 가능한 시스템의 설계할 능력에 대해서 입증하는 데 도움이 되지 않는다.

#### 4. 마무리

- 몇가지 후속 질문 (follow-up questions)를 던질 수도 있고 스스로 추가 논의를 진행할 수도 있다.
- 개선 가능한 지점에 대해서 추가 질문할 떄에는 ‘비판적’ 사고를 요하는 것일 수 있으니 최대한 깊게 탐구해보자.
- 설계에 대해서 요약 설명을 한번 더 하는 것이 좋을 수도 있다.
- 오류가 발생하면 어떤 일이 발생하는지 따져보자
- 운영 이슈는 어떻게 해결 할 것인가?
- 미래의 닥칠 규모의 확장에 대해서는?
- 필요하지만 다루지 못했던 세부 개선사항들을 제안할 수 있다.

### Interview Tip

#### 해야할 것

- 질문을 통해 확인할 것 (clarification) - 명확하게 할 것 - 가정이 옳다고 생각하지 말자
- 문제의 요구사항을 이해할 것
- 정답이나 최선의 답안 같은 것은 없다는 것을 명심해라.
- 면접관이 여러분의 사고 흐름을 이해할 수 있도록 하라.
- 가능하다면 여러 해법을 함께 제시하라
- 개략적인 설계에 면접관이 동의하면 각 컴포넌트의 세부 사항을 설명하기 시작하라.
- 면접관의 아이디어를 이끌어 낼 것
- 포기하지 마라

#### 하지 말아야할 것

- 전형적인 면접 문제들에도 대비하지 않은 상태에서 면접 장에 가지마라
- 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제시하지 말 것
- 처음부터 특정 컴포넌트의 세부 사항을 너무 길이 설명하지 말 것
- 진행 중에 막혔다면, 힌트를 청하기를 주저하지 말 것
- 소통에 주저하지 말 것
- 설계안을 내놓는 순간 면접은 끝난다고 생각하지 마라.

#### 시간 배분은 ?

- 1단계 : 3~10분
- 2단계 : 10~15분
- 3단계: 10~25분
- 4단계 : 3분에서 5분

## 4장 - 처리율 제한 장치의 설계

클라이언트가 서비스에 보내는 트래픽의 처리율(rate)를 제어하기 위함이다. 사용자는 초당 2회 이상의 새글을 올릴 수 없다거나, 하는 경우를 의미한다.

- DoS 공격에 의한 자원 고갈(Resource starvation)을 방지한다.
- 비용을 절감할 수 있다. 어뷰징에 처리를 위한 많은 서버를 둘 필요가 없어진다.
- 서버의 과부하를 막는다.

### 1단계 - 문제 이해 및 설계 범위의 확정

질문

- 어떠한 종류의 처리 제한 장치인지?
- API호출을 제어하는지, IP 혹은 사용자 ID 혹은 다른 기준으로 제어를 하는지.
- 시스템의 규모는 어느 정도여야 하는지?
- 분산환경에서 처리할 수 있어야하는지?
- 애플리케이션 코드에 포함되어도 되는지
- rate limit에 걸렸다면 사용자에게 알려줘야 하는지?

요구사항

- 설정된 처리율을 초과하는 요청은 정확하게 제한한다.
- 낮은 응답시간 : 이 처리율 제한 장치는 HTTP 응답 시간에 나쁜 영향을 주어서는 곤란하다
- 가능한 한 적은 메모리를 사용할 것
- 분산형 처리율 제한 : 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야한다
- 예외 처리 : 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주어야 한다
- 높은 결함 감내성 (fault tolerance - 내결함성) : 제한 장치에 장애가 생겨도 전체 시스템에는 영향을 주어서는 안된다

### 2단계 - 개략적인 설계안 제시 및 동의 구하기

처리율 제한 장치는 어디에 둘까? - 클라이언트 / 미들웨어 / 서버

- API Gateway에서도 이러한 기능을 제공하긴 하는데 처리율 지원을 제공하는 미들웨어일 뿐이다.

- 서버측 구현을 쓰기 위해서는 프로그래밍언어, 캐시 서비스가 충분히 효율(성능)이 좋아야 한다.
- 사업에 필요한 처리율 제한 알고리즘을 찾아라!
- MSA를 사용하고 있다면 API Gateway에 포함시켜야할 수 있다.
- 충분한 인력이 없다면 상용 API Gateway를 사용해라.

처리율 제한 알고리즘의 종류

- Token bucket : 간단하고 보편적으로 사용된다. ex: Amazon, Stripe
    - 특징
        - 하나의 버킷에 토큰을 주기적으로 채우며, 최대 치가 넘어가면 더이상 공급하지 않는다.
        - 하나의 요청을 처리할 때 마다 버킷의 토큰을 감소시킨다.
        - 인자로써 bucket size - refill rate(공급률) 를 받는다.
        - 비즈니스 규칙에 따라, 대상에 따라, 처리율에 따라서 설정해야하는 버킷의 크기와 수가 달라질 수 있다.
    - 장점
        - 구현이 쉽다
        - 메모리 사용 측면에서도 효율적이다(?)
        - 짧은 시간에 집중되는 트래픽도 처리 가능하다
    - 단점
        - bucket size와 refill rate의 튜닝이 까다로울 것
- Leaky bucket
    - 특징
        - token bucket과 비슷하지만 요청 처리율이 고정되어 있다.
        - 요청이 도착하면 큐가 가득 차 있는지 체크한다.
            - 가득 차 있다면 요청을 버린다.
            - 자리가 있다면 큐에 요청을 입력한다.
        - 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.
    - 인자
        - 버킷 크기 : 큐 사이즈
        - 처리율 : 초당 처리율
    - 장점
        - 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적이다
        - 고정된 처리율을 갖고 있기 때문에 안정적인 출력이 필요한 경우 적합하다. stable outflow rate
    - 단점
        - 트래픽이 몰리는 경우 오래된 요청이 쌓이고, 제떄 처리하지 못한다면 최신 요청들이 버려지게된다.
            - 오래된 요청 중 클라이언트가 임의로 요청을 중지한 경우 큐에서 제거되지 않으면 최신 요청이 버려질 순 있다.
        - 인자를 튜닝하기 까다롭다.
- Fixed window counter
    - 특징
        - 타임라인(timeline)에서 고정된 간격의 윈도우(폭, window)로 나누고 각 윈도우 마다 카운터를 붙힌다.
        - 요청을 받을 때 카운터를 증가시킨다.
        - 임계치에 도달하면 새로운 요청은 새 윈도우가 열릴 때까지 버려진다.
        - 윈도우 경게 부근의 순간적으로 많은 트래픽이 집중되면 더 많은 요청이 처리될 수 있다. (허용 한도의 2배)
    - 장점
        - 메모리 효율이 좋다
        - 이해하기 쉽고
        - 닫히는 시점에 카운터를 초기화 하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.
    - 단점
        - 경계부분에 일시적으로 많이 몰리면 기대했던 시스템 처리한도보다 많은 양을 처리하게 된다.
- Sliding window log
    - 특징
        - timestamp를 정렬된 집합에 저장한다. (ex: Redis sorted set)
        - 새 요청이 오면 요청의 기준으로 윈도우의 시작 지점보다 오래된 로그들을 삭제한다.
        - 새 요청의 타임 스탬프는 로그에 추가한다.
        - 로그의 크기가 허용치보다 작거나 같으면 요청을 시스템에 전달한다. 그렇지 않은 경우엔 처리를 거부한다.
    - 장점
        - 어느 순간의 윈도우를 포더라도 시스템의 처리율 한도를 넘지 않는다.
    - 단점
        - 다량의 메모리를 사용한다. 거부된 타임스탬프도 보관하기 때문이다.
- Sliding window counter
    - 특징
        - 고정 윈도우를 둔다.
        - 다만, 현재 시점의 요청의 개수를 계산하는 방식을 `현재 요청 count + 이전 요청 count * 직전 1분(초)가 겹치는 비율` 으로 계산한다.
        - 완전하게 정확하지는 않지만 - 유의미하다
    - 장점
        - 이전 시간대의 평균 처리율에 따라 현재 윈도우 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응함.
        - 메모리 효율이 좋음
    - 단점
        - 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기에 다소 느슨함 - 고정 윈도우 폭과 같은 문제가 발생할 수 있음
        - cloudflare에서 실시했던 실험을 기준으론 0.003% 불과함.

개략적인 아키텍처

- 카운터는 분산 시스템 카운터를 구현해야하므로 외부저장소에 저장해야하고, 디스크 기반 스토어보단 인메모리 기반 스토어가 처리량 측면에서 낫다
- 다양한 기능을 제공하는 redis가 좋다

### 3단계 - 상세 설계

- 처리율 제한 규칙은 어떻게 만들어지고 저장되는가
- 처리가 제한된 요청들은 어떻게 처리되는가

처리율 제한 규칙은 lyft의 경우에는 오픈소스를 사용하는데 보통의 경우 설정파일로 저장해서 사용한다고 소개한다.

처리율 한도 초과 트래픽 처리

- 즉시적으로 429응답으로 내보내거나, 큐에 담아 나중에 처리할 수도 있다.
- 즉시 응답을 보낼 때에는 헤더에 여러 정보를 담아서 어떠한 제한 장치에 걸렸는지 체크할 수 있다.

다이어그램 같은 경우에는 미들웨어가 있고 위에 설명한 내용을 그대로 표현한 형태라 굳이 메모하지 않는다.

분산환경에서의 처리율 제한 장치 구현

- 경쟁 조건
    - 여러 rate limiter 혹은 그것을 처리하는 프로세스가 떠있는 경우 경쟁조건이 발생할 수 있다.
    - 동시에 값을 읽어와 증가하고 저장하는 로직 (Read-Modify-Write)인 경우에는 Lost update가 발생할 수 있기 떄문이다.
    - 락은 성능을 떨어트리고 분산환경에 적합하지 않다.
    - luascript나 sorted set과 같은 자료구조를 쓸 수 있다.
    - note:
        - 애초에 `INCR` 와 같은 atomic operation이 보장되는 연산자를 쓰면 fixed / sliding window counter 전략에서는 유효하다.
        - 그 외에서는 저자가 말한대로 `SORTED SET` 을 써야한다. 다만 sorted set을 쓰더라도
- 동기화
    - 위에 언급한 문제로 redis(외부저장소)를 써야한다.
    - sticky session은 달콤하고 쉽지만 좋지못한 선택지다. - 유연하지도 않고 확장가능하지도 않다.
- 성능 최적화
    - multi region 서비스라면 어떻게 접근해야할까?
        - 우선 굉장히 먼 사용자를 위해서 사용자를 기준으로 가장 가까운 region(edge server) 서버를 두고 그곳으로 요청을 보내도록 하여 지연시간을 최소화할 수 있다.
        - rate limiter간의 동기화를 위해서 최종 일관성 모델을 사용할 수 있따.
            - note : 초단위 bucket이라면 이 모델이 사실상 사용이 불가능할 수 있다. 데이터가 전파되는대까지 보통 200~400ms정도 걸린다고 한다면 의미가 없는 최종 일관성 모델이 될 수 있다.
- 모니터링
    - 이러한 제한기가 옳바르게 (의도된 대로) 작동하고 있는지 체크하기 위해서는 모니터링을 통해 확인해야한다.

### 마무리

- hard, soft 처리율 제한
    - hard 는 임계치를 절대 넘어서는 안되고
    - soft 는 일시적으로 넘어설 수 있다는 것
- 계층 별로 처리율 제한 기준을 다르게 가져갈 수 있다.
- 처리율 제한은 최대한 회피하는 것이 좋다.
    - 클라이언트 측 캐시를 이용하여 요청을 줄인다.
    - 예외나 에러를 처리하는 코드를 도입하여, 클라이언트가 예외적인 상황으로부터 우아하게 복구될 수 있도록 한다.
    - 재시도 로직을 구현할 때는 충분한 백오프 시간을 둔다.