- [처리율 제한 장치의 설계](#처리율-제한-장치의-설계)
  - [rate limiter 요구 사항](#rate-limiter-요구-사항)
  - [처리율 제한 장치의 구현](#처리율-제한-장치의-구현)
  - [처리율 제한 알고리즘](#처리율-제한-알고리즘)
    - [토큰 버킷 알고리즘](#토큰-버킷-알고리즘)
    - [누출 버킷 알고리즘](#누출-버킷-알고리즘)
    - [고정 윈도 카운터 알고리즘](#고정-윈도-카운터-알고리즘)
    - [이동 윈도 로깅 알고리즘](#이동-윈도-로깅-알고리즘)
    - [이동 윈도 카운터 알고리즘](#이동-윈도-카운터-알고리즘)
    - [rate limiter의 개략적인 아키텍처](#rate-limiter의-개략적인-아키텍처)
  - [분산 환경에서의 rate limiter](#분산-환경에서의-rate-limiter)
  - [rate limiter 성능 최적화](#rate-limiter-성능-최적화)
  - [모니터링](#모니터링)
  - [추가로 면접에서 얘기해볼만한 것들](#추가로-면접에서-얘기해볼만한-것들)

# 처리율 제한 장치의 설계

**네트워크 시스템에서 처리율 제한 장치(rate limiter)는 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)를 제어하기 위한 장치이다.**

`rate limiter`에 정의된 `임계치`(threshold)를 넘어서면 추가로 도달한 모든 호출은 처리가 중단(block)된다.

rate limiter는 특정 상황에서 필요한데, 몇 가지 예를 들어보면 다음과 같다.

- **DoS(Denial of Service) 공격에 의한 자원 고갈(resource starvation) 방지**
- **비용 절감**
  - e.g. 제3자(third-party) API 사용량에 따라 사용료를 지불해야한다면 이를 절약해볼 수도 있다.
- **서버 과부하 방지**
  - 봇(bot)에서 오는 트래피이나 사용자의 잘못된 이용패턴으로 유발된 트래픽을 걸러낼 수 있다.
- **+외부 서비스 트래픽 제어 요청**
  - 실제로 협역하는 외부 서비스(신용조회 등)에서 트래픽 제어를 요청할 수도 있다.

## rate limiter 요구 사항

**보통 rate limiter에 대한 요구사항은 다음과 같은 것들이 있을 수 있다.**

- `정확한 제한`: 설정된 초과율을 초과하는 요청은 정확하게 제한한다.
- `낮은 응답시간`: HTTP latency에 부정적 영향을 주어서는 곤란함.
- `분산 시스템 고려`: 분산형 처리율 제한(distributed rate limiting)
- `예외 처리`: 요청이 제한되었을 때 확실한 피드백 e.g. 429(Too Many Request)
- `높은 결함 감내성(fault tolerance)`: 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어선 안됨(**no SPOF**)

## 처리율 제한 장치의 구현

**사실상 클라이언트/서버 어디서든 구현할 수 있지만 어디에 두느냐에 각 트레이드오프에 따라 안정성(신뢰성)과 효율성, 유연성에서 차이가 날 수 있다. 즉 상황에 맞추어 나름 최적의 선택을 할 뿐. 정답은 없다.**

- `클라이언트 측에 둔다면`: 클라이언트 요청을 쉽게 위변조 가능하므로 안정적이지 않음
- `서버 측에 둔다면`: 안정성을 챙겨갈 수 있음 그리고 이는 효율성, 유연성 면에서 API gateway(middleware)에 두느냐 API서버에 두느냐에 따라 디테일이 달라짐
  - `API gateway를 이용하면`: 만약에 MSA 구조라면 API gateway를 미들웨어로 두어 처리율 제한을 전체적으로 한 번에 적용할 수 있기 때문에 생산성면에서 효율적일 수 있다.
  - `API 서버를 이용하면`: 요구사항에 따라 특정 서비스에 대해서만 처리율 제한을 해야한다면 API 서버에서 구현해야할 수도 있다. e.g. 외부 서비스
- **note;**
  - 보통 클라우드에서 제공하는 완전관리형(fully-managed) API gateway는 middleware 역할로 처리율 제한, SSL 종단(termination), authentication, whitelist 등을 지원한다.
  - 요즘에는 k8s에서 같은 pod(instance)안에 미들웨어 역할을 하는 서버를 하나를 더 두는 sidecar패턴으로 middleware를 관리하기도 한다.
  - 매번 그렇지만 운영환경에서의 트레이드를 오프를 고려해서 적절한 방식을 고려하자. 회사의 기술스택, 엔지니어링 인력, 우선순위, 목표에 따라 달라질 수도 있다.

## 처리율 제한 알고리즘

처리율 제한을 구현을하는 알고리즘은 다음과 같이 여러가지인데 각각에 대해 알아보자.

모두 외울 필요는 없고 적절한 상황에 어떤 것을 활용하는 것이 좋은가 정도를 이해해보면 좋을 것 같다.

- `토큰 버킷 알고리즘`(token bucket)
- `누출 버킷 알고리즘`(leaky bucket)
- `고정 윈도 카운터`(fixed window counter)
- `이동 윈도 로그`(sliding window log)
- `이동 윈도 카운터`(sliding window counter)

### 토큰 버킷 알고리즘

**토큰 버킷을 두고 버킷에 담긴 토큰만큼의 요청을 처리한다**

- 기업들에서 보편적으로 사용되어 레퍼런스가 많다. 아마존, 스트라이프가 API요청을 통제(throttle)하기 위해 이 알고리즘을 활용한다.
- **동작 원리는 다음과 같다**
  - 먼저 여기서 제시하는 숫자들은 유동적일 수 있으니 유의하자.
  - 기본적으로 버킷에 요청을 처리할 수 있는 토큰(일종의 입장권)을 저장한다
    - e.g. 용량이 4인 버킷에 매초 2개의 토큰을 추가하고
    - 버킷이 가득 차면 추가로 공급된 토큰은 버려진다(overflow)
  - 각 요청이 처리될때 해당 버킷에서 토큰을 하나 꺼낸 후 요청을 처리한다.
    - 버킷에 토큰이 없을 때 들어온 요청은 그대로 버려진다(dropped)
  - 이렇게 하면 처리율을 제한할 수 있다.
- 정리해보면 다음 두 가지 값을 적절히 튜닝해볼 수 있을 것 같다.
  - **버킷 크기**: 버킷에 담을 수 있는 토큰의 최대 개수
  - **토큰 공급률(refill rate)**: 초당 몇 개의 토큰을 버킷에 공급할 것인가
- 버킷을 여러개 사용할 수도 있다.
  - API Endpoint마다, IP 주소별로, 전체적인 시스템의 처리율을 제한하고 싶다면 적절한 수의 버킷을 배치해야 한다.
- `장점`
  - 구현이 쉽고
  - 메모리 사용 측면에서 효율적이며
  - 짧은 시간에 집중되는 트래픽(burst of traffic)도 처리 가능하다.
- `단점`
  - 버킷의 크기와 토큰 공급률을 튜닝하는 것이 굉장히 까다롭다

### 누출 버킷 알고리즘

**토큰 버킷 알고리즘과 유사하지만, 요청 처리율이 고정되어 있다는 점이 다르다.**

- 보통 FIFO 큐로 구현한다.
- **동작원리는 다음과 같다.**
  - 요청이 도착하면 큐에 요청을 담을 수 있는지 확인하고 요청을 빈자리에 담는다.
  - 큐가 가득차 있는 경우 요청을 버리고
  - 지정된 시간마다 큐에서 요청을 꺼내 처리한다.
- 누출 알고리즘도 다음 두 가지 값을 적절히 튜닝해볼 수 있을 것 같다.
  - **버킷 크기**: 큐 사이즈
  - **처리율**(outflow rate): 지정된 시간당 몇 개의 요청을 처리할 것인가
- `장점`
  - 큐의 크기가 제한되어 메모리 사용량 측면에서 효율적
  - **고정된 처리율을 가지고 있어 안정된 출력(stable outflow rate)이 필요한 경우 적합**
- `단점`
  - 단시간에 많은 트래픽이 몰리는 경우 많은 최신 요청들이 버려지게 될 수 있음
  - 버킷 크기, 처리율을 튜닝하기 까다로움

### 고정 윈도 카운터 알고리즘

**단순히 일정 구간을 윈도우로 지정하고 카운트한다.**

- **동작원리는 다음과 같다.**
  - 타임라인(timeline)을 고정된 간격의 윈도(window)로 나누고, 각 윈도마다 카운터(counter)를 붙인다.
  - 요청이 접수될 때마다 카운터 +1
  - 카운터 값이 임계치에 도달하면 새로운 요청을 새 윈도가 열릴때까지 버려진다.
- **윈도의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 일정 구간에서 윈도에 할당된 양보다 많은 요청수를 처리할 수도 있다.**
- `장점`
  - 메모리 효율이 좋고
  - 단순해서 이해하기 쉽다.
  - 윈도가 닫히는 시점에 카운터를 초기화하므로 특정한 트래픽 패턴을 처리하기에 적합하다.
- `단점`
  - 윈도 경계 부근에 일시적 트래픽이 많이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.

### 이동 윈도 로깅 알고리즘

**고정 윈도 카운터 알고리즘의 단점인 윈도 경계 부근 일시적 대량 트래픽을 개선하기 위해 이동 윈도 로깅 알고리즘을 활용해볼 수 있다.**

**이 알고리즘은 쉽게 말해 요청의 timestamp를 시간 순으로 정렬해 로그로 저장하고, 이후에 요청이 오면 해당 요청의 timestamp를 기준으로 이전에 얼마만큼의 요청 로그가 쌓여있는지 검사하여 처리량을 조절한다.**

- **동작원리는 다음과 같다.**
  - 요청의 `timestamp`를 로그로 남겨 요청 기록을 추적한다. 보통 redis의 정렬 집합(sorted set)같은 캐시에 보관한다.
  - 새 요청이 오면 지정한 시간 범위를 벗어나 만료된 타임스탬프는 제거하고
  - 새 요청의 timestamp를 log로 기록한다
  - log의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달하고, 그렇지 않은 경우 처리를 거부한다.
- `장점`
  - 윈도를 시간에 기반해 움직이므로 처리율 제한 매커니즘이 아주 정교하다. 어느 순간의 윈도를 바라보아도 허용되는 요청의 개수는 시스템의 처리율 한도를 넘기지 않는다.
- `단점`
  - 거부된 요청의 timestamp도 보관하기 때문에 다량의 메모리를 사용한다.

### 이동 윈도 카운터 알고리즘

`고정 윈도 카운터 알고리즘`과 `이동 윈도 로깅 알고리즘` 을 결합한 것이다. 이 알고리즘을 구현하는 데는 두 가지 접근법이 사용될 수 있는데, 그 중 하나는 다음과 같다.

- **동작원리**
  - 1분당 7개를 제한하는 상황에서 이전 윈도에서 요청이 5개 오고 현재 윈도에서 30% 시점에 요청이 3개가 발생했다면, 현재 윈도에 몇 개의 요청이 온 것으로 보고 처리해야 할까?를 다루는 알고리즘으로 다음과 같이 계산한다.
  - 현재 윈도의 요청 수 계산법 = `현재 윈도의 요청 수`(3) + `직전 1분간의 요청 수`(5) x `이동 윈도와 직전 1분이 겹치는 비율`(70%) = 6.5개
  - 6.5개를 내림하거나 올림하는 건 선택사항이다.
- `장점`
  - 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
  - 메모리 효율이 좋다.
- `단점`
  - 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다. 사실 이건 크게 문제가 되지 않는데, 실제로 Cloudflare에서 실시했던 실험에 따르면 40억 개의 요청 가운데 시스템의 실제 상태와 맞지 않게 허용되거나 버려진 요청은 0.003%에 불과했다.

### rate limiter의 개략적인 아키텍처

처리율 제한 알고리즘의 기본 아이디어는 단순하다. 접수된 요청 수(카운터)를 트래킹하고 이를 기반으로 요청을 제어한다.

고려할만한 것들은 다음과 같다

- **제한하는 기준은 무엇인가?(요구사항)**
  - 사용자별
  - IP 주소별
  - API 엔드포인트나 서비스 단위
- 카운터는 어디에 둘 것인가?
  - 디스크 접근 때문에 느린 database는 사용하기 힘들다
  - 메모리상에서 동작하는 캐시가 바람직하다. 빠르고 시간에 기반한 만료 정책도 지원한다

## 분산 환경에서의 rate limiter

분산 환경에서는 병렬 스레드를 지원하도록 해야해서 `경쟁 조건(race condition)`과 `동기화 이슈`라는 어려운 두 문제를 풀어야한다.

- `경쟁 조건`
  - 경쟁 조건을 해결하기 위해 가장 널리 쓰이는 방법은 lock이다.
  - 그러나 lock은 성능 저하의 요인이기에 다른 두 가지로 `루아 스크립트(Lua script)`, `redis의 sorted set`을 사용할 수 있다.
- `동기화 이슈`
  - 수백만 사용자를 지원하려면 한 대의 처리율 제한 장치 서버로는 충분하지 않을 수 있다.
  - 여러 대의 처리율 제한 장치 서버를 두면 동기화 이슈가 발생하는데 이는 다음과 같이 풀어볼 수 있다.
  - 핵심은 한 곳에서 응집하거나, 계속 한 곳만 바라보게 해야한다.
    - **고정 세션(sticky session)**
    - **redis같은 별도의 영속성 layer 활용**

## rate limiter 성능 최적화

- 여러 데이터 센터를 운영하여 지연시간 단축
- rate limiter 간에 데이터를 동기화할 때 최종 일관성 모델(eventual consistency model)을 사용

## 모니터링

구현한 rate limiter가 효과적으로 잘 동작하는지 확인해볼 필요가 있다. 몇가지 주요 지표를 살펴보자.

- **채택된 처리율 제한 알고리즘의 효율성**
- **정의한 처리율 제한 규칙의 효율성**

깜짝 세일 같은 이벤트 때문에 트래픽이 급증할 때 처리율 제한 장치가 비효율적으로 동작한다면,
그런 트래픽 패턴을 잘 처리할 수 있도록 알고리즘을 바꾸는 것도 생각해봐야 한다.
이런 상황에서는 토큰 버킷이 적합할 것이다.
(토큰 버킷에 미리 토큰을 넣어두는 식으로 활용해볼 수 있을 것 같다)

## 추가로 면접에서 얘기해볼만한 것들

- `경성(hard) 또는 연성(soft) 처리율 제한`
  - 경성 처리율 제한: 요청의 개수는 임계치를 절대 넘어설 수 없다.
  - 연성 처리율 제한: 잠시 동안은 임계치를 넘어설 수 있다.
- `다양한 계층에서의 처리율 제한`
  - iptables를 이용한 IP주소에 처리율 제한 적용도 가능 (L3)
- `처리율 제한을 회피하는 방법. 클라이언트를 어떻게 설계하는 것이 최선인가?`
  - 클라이언트 측 캐시를 사용해 API 호출 횟수를 줄인다
  - 처리율 제한의 임계치를 이해하고, 짧은 시간 동안 너무 많은 메시지를 보내지 않도록 한다.
  - 예외, 에러를 처리하는 코드를 추가하여 클라이언트가 예외적 상황을 우아하게(gracefully) 복구될 수 있도록 한다.
  - retry 로직에 충분한 back-off 시간을 둔다.
